{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basic Stream').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileSchema = spark.read.json('D:/Dataset/activity-data/')\n",
    "fileSchema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fileSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema = fileSchema.schema\n",
    "act_df = spark.readStream.schema(dataSchema).option('maxFilesPerTrigger', 1).json('D:/Dataset/activity-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| gt|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|       sit|12309|\n",
      "|      walk|13256|\n",
      "|  stairsup|10452|\n",
      "|      bike|10796|\n",
      "|      null|10449|\n",
      "|     stand|11384|\n",
      "|stairsdown| 9365|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|31357|\n",
      "|     stand|34154|\n",
      "|       sit|36929|\n",
      "|      walk|39768|\n",
      "|      bike|32390|\n",
      "|      null|31343|\n",
      "|stairsdown|28094|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|52260|\n",
      "|     stand|56924|\n",
      "|       sit|61547|\n",
      "|      walk|66280|\n",
      "|      bike|53984|\n",
      "|      null|52239|\n",
      "|stairsdown|46825|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|62710|\n",
      "|     stand|68309|\n",
      "|       sit|73855|\n",
      "|      walk|79536|\n",
      "|      bike|64781|\n",
      "|      null|62688|\n",
      "|stairsdown|56192|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|  stairsup| 83614|\n",
      "|     stand| 91079|\n",
      "|       sit| 98471|\n",
      "|      walk|106048|\n",
      "|      bike| 86377|\n",
      "|      null| 83584|\n",
      "|stairsdown| 74922|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions', 1)\n",
    "act_count = act_df.groupBy('gt').count()\n",
    "act_querry = act_count.writeStream.queryName('ActivityQuery2') \\\n",
    "    .format('memory') \\\n",
    "    .outputMode('complete') \\\n",
    "    .start()\n",
    "\n",
    "for x in range (6):\n",
    "    spark.sql('SELECT * FROM ActivityQuery2').show()\n",
    "    sleep(5)\n",
    "    \n",
    "act_querry.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
